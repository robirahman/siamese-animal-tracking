from exclude_tortoise import *
from model.siamese.model_generator import create_model, base_models
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_addons as tfa
from tqdm.keras import TqdmCallback
from data.data_generator import DataGenerator
from model.siamese.config import cfg
from datetime import datetime
import numpy as np
import io


def embed_missing_tortoise(tortoise_number: int):
    """
    Embeds the tortoise_number-th tortoise usine a model trained on every tortoise except that one.
    This function should store and/or return the distance from that tortoise's embedding to the other classes.
    For now, it saves embeddings produced by each training dataset.
    """

    ALL_IMAGES = 'C:/Users/robir/OneDrive/Documents/GitHub/csci-e-599/siamese-animal-tracking/data/filter_aug'

    dataset_folder = exclude_tortoise(ALL_IMAGES, tortoise_number)
    train_data_folder = dataset_folder + "/train"
    test_data_folder = dataset_folder + "/test"

    TRAINABLE = True

    base_model = list(base_models.keys())[0]  # MobileNetV2, ResNet101V2, EfficientNetB5

    WEIGHTS_DIR = "model/siamese/weights"
    datatype = 'train'

    model = create_model(trainable=TRAINABLE, base_model=base_model)

    ds_generator = DataGenerator(
        file_ext=["png", "jpg"],
        folder_path=train_data_folder,
        exclude_aug=True,
        step_size=1
    )

    learning_rate = cfg.TRAIN.LEARNING_RATE
    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4) #DLiske the orig code had lr instead of learning_rate
    loss_func = tfa.losses.TripletSemiHardLoss() # DLiske comment only: The triplets are generated by TF

    model.compile(loss=loss_func, optimizer=optimizer, metrics=[])

    checkpoint = tf.keras.callbacks.ModelCheckpoint(
        WEIGHTS_DIR + "/" + base_model + "/siam-{epoch}-"+str(learning_rate)+"-"+"_{loss:.4f}.h5",
        monitor="loss",
        verbose=0,
        save_best_only=True,
        save_weights_only=True,
        mode="min",
        )
    stop = tf.keras.callbacks.EarlyStopping(monitor="loss", patience=cfg.TRAIN.PATIENCE, mode="min", restore_best_weights=True)

    logdir = "logs/fit/" + datetime.now().strftime("%Y%m%d-%H%M%S")
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)

    history = model.fit(
        ds_generator,
        #epochs=cfg.TRAIN.EPOCHS,
        epochs = 75,
        callbacks=[tensorboard_callback, checkpoint, TqdmCallback(verbose=0), stop],
        verbose=1
    )

    dataset = ds_generator.get_dataset()
    results = model.predict(dataset)

    np.savetxt(f"vecs-{datatype}-{base_model}-{tortoise_number}.tsv", results, delimiter="\t")
    out_m = io.open(f"meta-{datatype}-{base_model}-{tortoise_number}.tsv", "w")
    for img, labels in tfds.as_numpy(dataset):
        [out_m.write(str(x) + "\n") for x in labels]
    out_m.close()

    # merge all embeddings per class
    per_class = {}
    idx = 0
    for img, labels in tfds.as_numpy(dataset):
        for class_id in labels:
            if class_id not in per_class:
                per_class[class_id] = []
            per_class[class_id].append(results[idx])
            idx += 1

    mean_values = None
    labels = None
    # calculate average value for each class
    for class_id, values in per_class.items():

        matrix = np.array(values)
        mean_val = np.mean(matrix, axis=0)
        if mean_values is None:
            mean_values = np.array([mean_val])
        else:
            mean_values = np.concatenate((mean_values, np.array([mean_val])), axis=0)
        if labels is None:
            labels = np.array([class_id], dtype='U20')
        else:
            labels = np.concatenate((labels, [class_id]), axis=0, dtype='U20')

    np.save(f'/names-{tortoise_number}.npy', labels)

    datatype = 'train'
    # DLiske (I added b/c it seems like we shouldn't overwrite the avg embeddings if we're doing this on Test...)
    if datatype == 'train':  # DLiske
        # save avg embedding per class to be used as visualization and for further processing
        np.savetxt(f"vecs-conc-{base_model}-{tortoise_number}.tsv", mean_values, delimiter="\t")
        # np.savetxt(f"meta-conc-{base_model}.tsv", labels, fmt="%i", delimiter="\t")
        np.savetxt(f"meta-conc-{base_model}-{tortoise_number}.tsv", labels, fmt="%s", delimiter="\t") # D LISKE


if __name__ == "__main__":
    embed_missing_tortoise(tortoise_number=0)
