{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51849ad3",
   "metadata": {},
   "source": [
    "# Embedding distance thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67d81b",
   "metadata": {},
   "source": [
    "The idea here is to train the siamese network using different datasets consisting of all but one tortoise, then seeing how far the embedding of that tortoise is from the images which the network was trained on. This should give an idea of what the threshold should be for determining a tortoise is new, as opposed to one we have encountered before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838194d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c40339",
   "metadata": {},
   "outputs": [],
   "source": [
    "turtles = [None]\n",
    "for turtle in turtles:\n",
    "    # make dataset without turtle\n",
    "    # train siamese network to embed and distinguish turtles\n",
    "    # get the network's embedding of the excluded turtle\n",
    "    # store distance of excluded turtle's embedding to all other embeddings\n",
    "    pass\n",
    "# plot histogram of embeddings of each turtle when each was excluded from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a08d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process for one dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "create model (from base model, MobileNetV2)\n",
    "generate dataset\n",
    "configure learning rate, optimizer, loss function\n",
    "compile model\n",
    "configure checkpoints, early stopping, patience\n",
    "fit model and save history\n",
    "use model to predict dataset\n",
    "calculate embedding distance on omitted class\n",
    "save embedding distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "need to write a script to do the above, then save it to a module"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from exclude_tortoise import *\n",
    "from model.siamese.model_generator import create_model, base_models\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tqdm.keras import TqdmCallback\n",
    "from data.data_generator import DataGenerator\n",
    "from model.siamese.config import cfg\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Delete 'turtles_except_0' before testing\n",
    "TURTLE_NUMBER = 0  # 0 through 26\n",
    "ALL_IMAGES = 'C:/Users/robir/OneDrive/Documents/GitHub/csci-e-599/siamese-animal-tracking/data/filter_aug'\n",
    "\n",
    "dataset_folder = exclude_tortoise(ALL_IMAGES, TURTLE_NUMBER)\n",
    "train_data_folder = dataset_folder + \"/train\"\n",
    "test_data_folder = dataset_folder + \"/test\"\n",
    "\n",
    "TRAINABLE = True\n",
    "\n",
    "base_model = list(base_models.keys())[0]  # MobileNetV2, ResNet101V2, EfficientNetB5\n",
    "\n",
    "WEIGHTS_DIR = \"model/siamese/weights\"\n",
    "datatype = 'train'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model = create_model(trainable=TRAINABLE, base_model=base_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Found 92 files for 23 unique classes\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.keras.utils.plot_model(\n",
    "        model,\n",
    "        to_file=f\"assets/{base_model}_model_fig.png\",\n",
    "        show_shapes=True,\n",
    "        expand_nested=True,\n",
    "    )\n",
    "except ImportError as e:\n",
    "    print(f\"Failed to plot keras model: {e}\")\n",
    "\n",
    "ds_generator = DataGenerator(\n",
    "    file_ext=[\"png\", \"jpg\"],\n",
    "    folder_path=train_data_folder,\n",
    "    exclude_aug=True,\n",
    "    step_size=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "learning_rate = cfg.TRAIN.LEARNING_RATE\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4) #DLiske the orig code had lr instead of learning_rate\n",
    "loss_func = tfa.losses.TripletSemiHardLoss() # DLiske comment only: The triplets are generated by TF\n",
    "\n",
    "model.compile(loss=loss_func, optimizer=optimizer, metrics=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    WEIGHTS_DIR + \"/\" + base_model + \"/siam-{epoch}-\"+str(learning_rate)+\"-\"+\"_{loss:.4f}.h5\",\n",
    "    monitor=\"loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"min\",\n",
    ")\n",
    "stop = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=cfg.TRAIN.PATIENCE, mode=\"min\", restore_best_weights=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0epoch [00:00, ?epoch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6e89f7d5f7a4ccab2657538f07a5035"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[1;32mIn [24]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m logdir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogs/fit/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m datetime\u001B[38;5;241m.\u001B[39mnow()\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      2\u001B[0m tensorboard_callback \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mTensorBoard(log_dir\u001B[38;5;241m=\u001B[39mlogdir)\n\u001B[1;32m----> 4\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mds_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#epochs=cfg.TRAIN.EPOCHS,\u001B[39;49;00m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m75\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtensorboard_callback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTqdmCallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[0;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\csci-e-599\\siamese-animal-tracking\\data\\data_generator.py:214\u001B[0m, in \u001B[0;36mDataGenerator.__getitem__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m    210\u001B[0m images \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimages\u001B[38;5;241m.\u001B[39mloc[\n\u001B[0;32m    211\u001B[0m     item \u001B[38;5;241m*\u001B[39m cfg\u001B[38;5;241m.\u001B[39mTRAIN\u001B[38;5;241m.\u001B[39mBATCH_SIZE : (item \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m cfg\u001B[38;5;241m.\u001B[39mTRAIN\u001B[38;5;241m.\u001B[39mBATCH_SIZE\n\u001B[0;32m    212\u001B[0m ]\n\u001B[0;32m    213\u001B[0m target \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mmap(DataGenerator\u001B[38;5;241m.\u001B[39mprocess_label)\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[1;32m--> 214\u001B[0m images \u001B[38;5;241m=\u001B[39m \u001B[43mimages\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpath\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDataGenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_image\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[0;32m    215\u001B[0m \u001B[38;5;66;03m#print(images.shape)\u001B[39;00m\n\u001B[0;32m    216\u001B[0m reshaped_images \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(images)\u001B[38;5;241m.\u001B[39mreshape(\n\u001B[0;32m    217\u001B[0m     (\n\u001B[0;32m    218\u001B[0m         images\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    222\u001B[0m     )\n\u001B[0;32m    223\u001B[0m )\n",
      "File \u001B[1;32m~\\.virtualenvs\\lib\\site-packages\\pandas\\core\\series.py:4542\u001B[0m, in \u001B[0;36mSeries.map\u001B[1;34m(self, arg, na_action)\u001B[0m\n\u001B[0;32m   4463\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\n\u001B[0;32m   4464\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4465\u001B[0m     arg: Callable \u001B[38;5;241m|\u001B[39m Mapping \u001B[38;5;241m|\u001B[39m Series,\n\u001B[0;32m   4466\u001B[0m     na_action: Literal[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   4467\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series:\n\u001B[0;32m   4468\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4469\u001B[0m \u001B[38;5;124;03m    Map values of Series according to an input mapping or function.\u001B[39;00m\n\u001B[0;32m   4470\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4540\u001B[0m \u001B[38;5;124;03m    dtype: object\u001B[39;00m\n\u001B[0;32m   4541\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4542\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4543\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_values, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex)\u001B[38;5;241m.\u001B[39m__finalize__(\n\u001B[0;32m   4544\u001B[0m         \u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmap\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4545\u001B[0m     )\n",
      "File \u001B[1;32m~\\.virtualenvs\\lib\\site-packages\\pandas\\core\\base.py:890\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action)\u001B[0m\n\u001B[0;32m    887\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    889\u001B[0m \u001B[38;5;66;03m# mapper is a function\u001B[39;00m\n\u001B[1;32m--> 890\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mmap_f\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m new_values\n",
      "File \u001B[1;32m~\\.virtualenvs\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2919\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\csci-e-599\\siamese-animal-tracking\\data\\data_generator.py:152\u001B[0m, in \u001B[0;36mDataGenerator.process_image\u001B[1;34m(image_path, to_input)\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_image\u001B[39m(image_path, to_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;124;03m        image_path: string\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    150\u001B[0m \n\u001B[0;32m    151\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 152\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocessing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_img\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNN\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mINPUT_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNN\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mINPUT_SIZE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m     image \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mpreprocessing\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mimg_to_array(image)\n\u001B[0;32m    156\u001B[0m     image \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(image, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[1;31mImportError\u001B[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    ds_generator,\n",
    "    #epochs=cfg.TRAIN.EPOCHS,\n",
    "    epochs = 75,\n",
    "    callbacks=[tensorboard_callback, checkpoint, TqdmCallback(verbose=0), stop],\n",
    "    verbose=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = ds_generator.get_dataset()\n",
    "results = model.predict(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.savetxt(f\"vecs-{datatype}-{base_model}.tsv\", results, delimiter=\"\\t\")\n",
    "out_m = io.open(f\"meta-{datatype}-{base_model}.tsv\", \"w\")#, encoding=\"utf-8\")\n",
    "for img, labels in tfds.as_numpy(dataset):\n",
    "    [out_m.write(str(x) + \"\\n\") for x in labels]\n",
    "out_m.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# merge all embeddings per class\n",
    "per_class = {}\n",
    "idx = 0\n",
    "for img, labels in tfds.as_numpy(dataset):\n",
    "    for class_id in labels:\n",
    "        if class_id not in per_class:\n",
    "            per_class[class_id] = []\n",
    "        per_class[class_id].append(results[idx])\n",
    "        idx += 1\n",
    "\n",
    "mean_values = None\n",
    "labels = None\n",
    "# calculate average value for each class\n",
    "for class_id, values in per_class.items():\n",
    "    #print(\"CLASS_ID\", class_id)#, values)\n",
    "    matrix = np.array(values)\n",
    "    mean_val = np.mean(matrix, axis=0)\n",
    "    if mean_values is None:\n",
    "        mean_values = np.array([mean_val])\n",
    "    else:\n",
    "        mean_values = np.concatenate((mean_values, np.array([mean_val])), axis=0)\n",
    "    if labels is None:\n",
    "        labels = np.array([class_id], dtype='U20')\n",
    "    else:\n",
    "        labels = np.concatenate((labels, [class_id]), axis=0, dtype='U20')\n",
    "\n",
    "np.save('/names.npy', labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datatype = 'train'\n",
    "# DLiske (I added b/c it seems like we shouldn't overwrite the avg embeddings if we're doing this on Test...)\n",
    "if datatype == 'train': # DLiske\n",
    "    # save avg embedding per class to be used as visualization and for further processing\n",
    "    np.savetxt(f\"vecs-conc-{base_model}.tsv\", mean_values, delimiter=\"\\t\")\n",
    "    #np.savetxt(f\"meta-conc-{base_model}.tsv\", labels, fmt=\"%i\", delimiter=\"\\t\")\n",
    "    np.savetxt(f\"meta-conc-{base_model}.tsv\", labels, fmt=\"%s\", delimiter=\"\\t\") #D LISKE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}